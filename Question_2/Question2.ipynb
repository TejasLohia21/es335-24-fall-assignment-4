{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a,b):\n",
    "    return np.sqrt(np.sum((a - b)**2))                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(N, D):\n",
    "    return np.random.rand(N, D)\n",
    "\n",
    "def generate_query(D):\n",
    "    return np.random.rand(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_knn(query, dataset, K):\n",
    "    distances = [distance(query, point) for point in dataset]\n",
    "    sorted_indices = np.argsort(distances)\n",
    "\n",
    "    k_sorted_points =  np.array([dataset[i] for i in sorted_indices[:K]])\n",
    "    k_sorted_distances = np.array(distances)[sorted_indices[:K]]\n",
    "\n",
    "    return sorted_indices[:K], k_sorted_points,  k_sorted_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N,D,K= 1000, 5, 10\n",
    "ds= generate_dataset(N,D)\n",
    "q= generate_query(D)\n",
    "if D==2:\n",
    "    plt.scatter(ds[:, 0], ds[:, 1])\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.title('Scatter plot of 2D Dataset')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n",
      "[508 576 743 972  44 731 250 148 124 128]\n",
      "[[0.18880225 0.89881759 0.48061463 0.02509819 0.29025713]\n",
      " [0.23831656 0.89943075 0.40399306 0.34239942 0.38415212]\n",
      " [0.0030833  0.97159352 0.50304068 0.31152268 0.32471155]\n",
      " [0.27152427 0.95949309 0.22054768 0.16690242 0.4779965 ]\n",
      " [0.32895058 0.85367267 0.43239671 0.18279736 0.50334501]\n",
      " [0.13749313 0.85925127 0.16984635 0.25746505 0.4861598 ]\n",
      " [0.24316426 0.95432088 0.43741774 0.22182947 0.14731658]\n",
      " [0.21392793 0.80113744 0.55656834 0.12313497 0.60877014]\n",
      " [0.16051373 0.93612223 0.68887516 0.24799755 0.3066494 ]\n",
      " [0.01215896 0.93522769 0.30348597 0.0258052  0.67729439]]\n",
      "[0.1857689  0.24937569 0.25017533 0.25543898 0.26914711 0.28540006\n",
      " 0.28814683 0.32720837 0.333737   0.34049964]\n"
     ]
    }
   ],
   "source": [
    "indices, points, distances=naive_knn(q, ds, K)\n",
    "print(points.shape)\n",
    "print(indices)\n",
    "print(points)\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KD Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDTree:\n",
    "    def __init__(self, data, leaf_size):\n",
    "        self.data = np.hstack((data, np.arange(len(data)).reshape(-1, 1))) ##stacking the indices\n",
    "        self.leaf_size = leaf_size\n",
    "        self.tree = self.build_kdtree(self.data)\n",
    "    \n",
    "    def build_kdtree(self, data, depth=0):\n",
    "        if len(data) <= self.leaf_size:\n",
    "            return data  \n",
    "        \n",
    "        axis = depth % (data.shape[1] - 1)  # Alternate splitting axis, ignore index column\n",
    "        sorted_data = data[data[:, axis].argsort()]\n",
    "        median_index = len(sorted_data) // 2\n",
    "        left = self.build_kdtree(sorted_data[:median_index], depth + 1)\n",
    "        right = self.build_kdtree(sorted_data[median_index + 1:], depth + 1)\n",
    "        \n",
    "        return (sorted_data[median_index], left, right)\n",
    "    \n",
    "    def query(self, query, K):\n",
    "        indices, distances = self._query(self.tree, query, K, depth=0) \n",
    "        points = self.data[indices, :-1]\n",
    "        return indices, points, distances\n",
    "    \n",
    "    def _query(self, node, query, K, depth):\n",
    "    \n",
    "        if isinstance(node, np.ndarray): #leaf node is an array\n",
    "            points = node[:, :-1] \n",
    "            original_indices = node[:, -1].astype(int)  \n",
    "            distances = np.array([distance(query, point) for point in points])\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            nearest_indices = original_indices[sorted_indices[:K]]\n",
    "            nearest_distances = distances[sorted_indices[:K]]\n",
    "            return nearest_indices, nearest_distances\n",
    "        \n",
    "        if isinstance(node, tuple) and len(node) == 3: # non-leaf node is a tuple (median point, left subtree, right subtree)\n",
    "            median, left, right = node\n",
    "            axis = depth % (query.shape[0])\n",
    "            \n",
    "            if query[axis] < median[axis]:\n",
    "                primary, other = left, right\n",
    "            else:\n",
    "                primary, other = right, left\n",
    "            \n",
    "            # Recursively search the primary side\n",
    "            indices, distances = self._query(primary, query, K, depth + 1)\n",
    "            \n",
    "            \n",
    "            if len(indices) < K or abs(query[axis] - median[axis]) < max(distances): # if the other tree's data also need to be combined\n",
    "                other_indices, other_distances = self._query(other, query, K, depth + 1)\n",
    "                combined_indices = np.concatenate([indices, other_indices])\n",
    "                combined_distances = np.concatenate([distances, other_distances])\n",
    "                sorted_combined = np.argsort(combined_distances)\n",
    "                indices = combined_indices[sorted_combined][:K]\n",
    "                distances = combined_distances[sorted_combined][:K]\n",
    "            \n",
    "            return indices, distances\n",
    "        \n",
    "       \n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of nearest neighbors: [508 576 743 972 731 250 148 124 128 854]\n",
      "Nearest points: [[0.18880225 0.89881759 0.48061463 0.02509819 0.29025713]\n",
      " [0.23831656 0.89943075 0.40399306 0.34239942 0.38415212]\n",
      " [0.0030833  0.97159352 0.50304068 0.31152268 0.32471155]\n",
      " [0.27152427 0.95949309 0.22054768 0.16690242 0.4779965 ]\n",
      " [0.13749313 0.85925127 0.16984635 0.25746505 0.4861598 ]\n",
      " [0.24316426 0.95432088 0.43741774 0.22182947 0.14731658]\n",
      " [0.21392793 0.80113744 0.55656834 0.12313497 0.60877014]\n",
      " [0.16051373 0.93612223 0.68887516 0.24799755 0.3066494 ]\n",
      " [0.01215896 0.93522769 0.30348597 0.0258052  0.67729439]\n",
      " [0.08493355 0.9788638  0.21929512 0.3956276  0.26531005]]\n",
      "Distances to nearest points: [0.1857689  0.24937569 0.25017533 0.25543898 0.28540006 0.28814683\n",
      " 0.32720837 0.333737   0.34049964 0.34055163]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree = KDTree(ds, leaf_size=20)\n",
    "\n",
    "\n",
    "indices, points, distances = tree.query(q, K)\n",
    "\n",
    "print(\"Indices of nearest neighbors:\", indices)\n",
    "print(\"Nearest points:\", points)\n",
    "print(\"Distances to nearest points:\", distances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH:\n",
    "    def __init__(self, dataset, num_hashes=5):\n",
    "        self.dataset = dataset\n",
    "        self.num_hashes = num_hashes\n",
    "        self.dataset_augmented = np.hstack((self.dataset, np.ones((self.dataset.shape[0], 1))))  # Adding bias term\n",
    "        self.hashes = self._generate_hashes()  # Hashes with bias term included\n",
    "\n",
    "    def _generate_hashes(self):\n",
    "        return np.random.randn(self.num_hashes, self.dataset.shape[1] + 1)\n",
    "\n",
    "    def _hash_(self, point):\n",
    "        point_augmented = np.append(point, 1)  \n",
    "        return np.sign(np.dot(self.hashes, point_augmented))  \n",
    "\n",
    "    def query(self, query, K):\n",
    "        query_hash = self._hash_(query)\n",
    "\n",
    "        hash_buckets = {}\n",
    "        for index, point in enumerate(self.dataset):\n",
    "            point_hash = tuple(self._hash_(point))  # Made it into a tuple so it can be used as a dictionary key\n",
    "            if point_hash not in hash_buckets:\n",
    "                hash_buckets[point_hash] = []\n",
    "            hash_buckets[point_hash].append(index)\n",
    "\n",
    "        query_hash_tuple = tuple(query_hash)\n",
    "\n",
    "        nearest_neighbors = self.find_k(query, hash_buckets.get(query_hash_tuple, []), K) # looking into same bucket\n",
    "\n",
    "        if len(nearest_neighbors) < K: #neighbouring buckets\n",
    "            for i in range(self.num_hashes):\n",
    "                if len(nearest_neighbors) >= K:\n",
    "                    break\n",
    " \n",
    "                modified_query_hash = list(query_hash_tuple)\n",
    "                modified_query_hash[i] = 1 - modified_query_hash[i]  # Flipping the ith hash value\n",
    "                modified_query_hash_tuple = tuple(modified_query_hash)\n",
    "                \n",
    "                if modified_query_hash_tuple in hash_buckets:\n",
    "                    remaining_neighbors = self.find_k(query, hash_buckets[modified_query_hash_tuple], K - len(nearest_neighbors))\n",
    "                    nearest_neighbors.extend(remaining_neighbors)\n",
    "\n",
    "        nearest_neighbors = sorted(nearest_neighbors, key=lambda x: x[1])[:K] \n",
    "\n",
    "        nearest_indices = [index for index, _ in nearest_neighbors]\n",
    "        nearest_points = self.dataset[nearest_indices]\n",
    "        nearest_distances = [dist for _, dist in nearest_neighbors]\n",
    "\n",
    "        return nearest_indices, nearest_points, nearest_distances\n",
    "\n",
    "    def find_k(self, query, bucket_indices, K):\n",
    "        distances = []\n",
    "        for index in bucket_indices:\n",
    "            point = self.dataset[index]\n",
    "            dist = distance(query, point) \n",
    "            distances.append((index, dist))\n",
    "\n",
    "        return sorted(distances, key=lambda x: x[1])[:K] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Point: [0.11266692 0.9322325  0.38959672 0.13000921 0.38139635]\n",
      "[508, 148, 583, 593, 999, 364, 761, 412]\n",
      "[[0.18880225 0.89881759 0.48061463 0.02509819 0.29025713]\n",
      " [0.21392793 0.80113744 0.55656834 0.12313497 0.60877014]\n",
      " [0.33565034 0.83473074 0.57266212 0.10849671 0.55249725]\n",
      " [0.20840855 0.72291725 0.69173774 0.12780284 0.60568076]\n",
      " [0.4865881  0.95498749 0.72282343 0.04510985 0.58884273]\n",
      " [0.34295209 0.90922486 0.88340219 0.01973479 0.54705592]\n",
      " [0.32059099 0.70603833 0.72078127 0.11239619 0.76921046]\n",
      " [0.16313142 0.88322389 0.89265186 0.14603094 0.76827729]]\n",
      "[0.18576890153757664, 0.32720837286017884, 0.34997062958318065, 0.4411087069082088, 0.549196484520224, 0.580523893594054, 0.595642026351071, 0.6387069317080944]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_hashes = 15 \n",
    "\n",
    "lsh = LSH(ds, num_hashes)\n",
    "nearest_indices, nearest_points, nearest_distances = lsh.query(q, K)\n",
    "\n",
    "print(\"Query Point:\", q)\n",
    "print(nearest_indices)\n",
    "print(nearest_points)\n",
    "print(nearest_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[508 576 743 972  44 731 250 148 124 128]\n",
      "[[0.18880225 0.89881759 0.48061463 0.02509819 0.29025713]\n",
      " [0.23831656 0.89943075 0.40399306 0.34239942 0.38415212]\n",
      " [0.0030833  0.97159352 0.50304068 0.31152268 0.32471155]\n",
      " [0.27152427 0.95949309 0.22054768 0.16690242 0.4779965 ]\n",
      " [0.32895058 0.85367267 0.43239671 0.18279736 0.50334501]\n",
      " [0.13749313 0.85925127 0.16984635 0.25746505 0.4861598 ]\n",
      " [0.24316426 0.95432088 0.43741774 0.22182947 0.14731658]\n",
      " [0.21392793 0.80113744 0.55656834 0.12313497 0.60877014]\n",
      " [0.16051373 0.93612223 0.68887516 0.24799755 0.3066494 ]\n",
      " [0.01215896 0.93522769 0.30348597 0.0258052  0.67729439]]\n",
      "[0.1857689  0.24937569 0.25017533 0.25543898 0.26914711 0.28540006\n",
      " 0.28814683 0.32720837 0.333737   0.34049964]\n"
     ]
    }
   ],
   "source": [
    "indices, points, distances=naive_knn(q, ds, K)\n",
    "print(indices)\n",
    "print(points)\n",
    "print(distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
